{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1dShNK-H-RL4iHe48AFIrJULfBoAYM6NR","authorship_tag":"ABX9TyN6LkcIOd0CWJEZOvdjzgfJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Wolydz42aUA7","executionInfo":{"status":"ok","timestamp":1667157652838,"user_tz":240,"elapsed":895,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}}},"outputs":[],"source":["import pandas as pd\n","#importing K nearest neighbors classifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import math\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["Question 5."],"metadata":{"id":"kWXSjxrCisp8"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Data Science Eugene Pinsky/Homework_7/bank_notes/data_banknote_authentication.csv\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"uw6QrMYUaj6Y","executionInfo":{"status":"ok","timestamp":1667157659768,"user_tz":240,"elapsed":1341,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}},"outputId":"01bc2c77-96f4-4c2f-9ab3-c6855d5eb6d5"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   variance  skewness  curtosis  entropy  class\n","0   3.62160    8.6661   -2.8073 -0.44699      0\n","1   4.54590    8.1674   -2.4586 -1.46210      0\n","2   3.86600   -2.6383    1.9242  0.10645      0\n","3   3.45660    9.5228   -4.0112 -3.59440      0\n","4   0.32924   -4.4552    4.5718 -0.98880      0"],"text/html":["\n","  <div id=\"df-e0897334-f774-439e-a0fa-81d01ef89848\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>variance</th>\n","      <th>skewness</th>\n","      <th>curtosis</th>\n","      <th>entropy</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.62160</td>\n","      <td>8.6661</td>\n","      <td>-2.8073</td>\n","      <td>-0.44699</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.54590</td>\n","      <td>8.1674</td>\n","      <td>-2.4586</td>\n","      <td>-1.46210</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.86600</td>\n","      <td>-2.6383</td>\n","      <td>1.9242</td>\n","      <td>0.10645</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.45660</td>\n","      <td>9.5228</td>\n","      <td>-4.0112</td>\n","      <td>-3.59440</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.32924</td>\n","      <td>-4.4552</td>\n","      <td>4.5718</td>\n","      <td>-0.98880</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0897334-f774-439e-a0fa-81d01ef89848')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e0897334-f774-439e-a0fa-81d01ef89848 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e0897334-f774-439e-a0fa-81d01ef89848');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["Q1."],"metadata":{"id":"pr0e4Ipcio3d"}},{"cell_type":"code","source":["#function to build passed model on given data\n","def build_model(model,data,features,labels):\n","\n","  #splitting dataset into features and class labels\n","  X = data[features]\n","  y = data[labels]\n","\n","  #defining scaler\n","  scaler = StandardScaler()\n","\n","  #splitting data each time 50:50 train test split\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.5,random_state=42)\n","\n","  #scaling training data (X_train)\n","  scaler.fit(X_train)\n","  X_train = scaler.transform(X_train)\n","\n","  #fitting classifier to training data\n","  model.fit(X_train,y_train)\n","\n","  #predicting labels and storing results in y_pred \n","  #X_test = scaler.transform(X_test)\n","\n","  y_pred = model.predict(X_test)\n","\n","  #computing accuracy\n","  accuracy  = round( accuracy_score(y_test,y_pred) *100,2)  \n","  \n","  return accuracy,y_test,y_pred,model\n"],"metadata":{"id":"8EDsFCyYv9BB","executionInfo":{"status":"ok","timestamp":1667157678607,"user_tz":240,"elapsed":434,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["logReg = LogisticRegression()\n","accuracy,y_test,y_pred,logReg = build_model(logReg,df,[\"variance\",\"skewness\",\"curtosis\",\"entropy\"],[\"class\"])\n","print(\"The accuracy of the Logistic Regression model: \"+str(accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIrjLdHFyrs2","executionInfo":{"status":"ok","timestamp":1667157682587,"user_tz":240,"elapsed":11,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}},"outputId":"e5bb470d-cd53-4ca6-c3e2-9e6cfed41db7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy of the Logistic Regression model: 84.11\n"]}]},{"cell_type":"markdown","source":["Q2."],"metadata":{"id":"uGyTNLfgi-mX"}},{"cell_type":"code","source":["def model_results(y_test,y_pred):\n","\n","  results_metrics = pd.DataFrame(columns = [\"TP\",\"FP\",\"TN\",\"FN\",\"accuracy\",\"TPR\",\"TNR\"])\n","\n","  #calcultaing true/false and positive/negative \n","  tn,fp,fn,tp = confusion_matrix(y_test,y_pred).ravel()\n","\n","  #calcultaing true positive rate\n","  tpr = tp / (tp + fn)\n","\n","  #calculating true negative rate\n","  tnr = tn / (tn + fp)\n","\n","  #appending results to dataframe\n","  results_metrics.loc[0] = [tp] + [fp] + [tn] + [fn] + [accuracy] + [round(tpr*100,2)] + [round(tnr*100,2)]\n","\n","  #returning results in tabular form\n","  return results_metrics"],"metadata":{"id":"VBpMdqhI1HZD","executionInfo":{"status":"ok","timestamp":1667157785373,"user_tz":240,"elapsed":3,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["results = model_results(y_test,y_pred)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"GEet6Dic1K7g","executionInfo":{"status":"ok","timestamp":1667157787812,"user_tz":240,"elapsed":10,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}},"outputId":"1d66a447-0d71-4123-9dde-3633e69e0d8e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      TP   FP     TN     FN  accuracy    TPR    TNR\n","0  191.0  0.0  386.0  109.0     84.11  63.67  100.0"],"text/html":["\n","  <div id=\"df-163bbf53-321e-4d98-ba91-3efb1016bf43\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TP</th>\n","      <th>FP</th>\n","      <th>TN</th>\n","      <th>FN</th>\n","      <th>accuracy</th>\n","      <th>TPR</th>\n","      <th>TNR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>191.0</td>\n","      <td>0.0</td>\n","      <td>386.0</td>\n","      <td>109.0</td>\n","      <td>84.11</td>\n","      <td>63.67</td>\n","      <td>100.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-163bbf53-321e-4d98-ba91-3efb1016bf43')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-163bbf53-321e-4d98-ba91-3efb1016bf43 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-163bbf53-321e-4d98-ba91-3efb1016bf43');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Q3."],"metadata":{"id":"PH2j5jZijMlv"}},{"cell_type":"markdown","source":["Logistic regression is better than my simple classifier on the following points:\n","\n","1. Logistic regression classifier has a better model accuracy (84.4%) than the  simple classifier (62.97%). \n","2. True negative rate is better for logistic regression (100%) than the simple classifier (98.69%) .\n","3. True positive rate is better for logistic regression (64.8%) than the simple classifier (18.09%) .\n"],"metadata":{"id":"johQScT4h2c3"}},{"cell_type":"markdown","source":["Q4."],"metadata":{"id":"OcKvDqBWjNyK"}},{"cell_type":"markdown","source":["Logistic regression is better than my KNN classifier on the following points:\n","\n","1. Logistic regression classifier has a better model accuracy (84.4%) than the KNN classifier (78.88%). \n","2. True negative rate is better for logistic regression (100%) than the KNN classifier (90.51%) .\n","3. True positive rate is better for KNN classifier (67.51%) than the logistic regression classifier (64.8%) .\n"],"metadata":{"id":"1E_caMd3iGIm"}},{"cell_type":"markdown","source":["Q5."],"metadata":{"id":"0hXVKDkWifMp"}},{"cell_type":"code","source":["#taking last four digits of BUID to be test set.\n","x = [4,3,9,8]\n","\n","y_pred = logReg.predict([x])\n","print(\"The result of Logistic regression classifer is: \")\n","if y_pred == 1 :\n","    print(\"\\tThe note is fake (class : 1)\")\n","else:\n","    print(\"\\tThe note is real (class : 0)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6E4Y7hEVilMh","executionInfo":{"status":"ok","timestamp":1667075956063,"user_tz":240,"elapsed":6,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}},"outputId":"c22e1b7f-6f34-455d-a7e0-30bb81fd166d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The result of Logistic regression classifer is: \n","\tThe note is real (class : 0)\n"]}]},{"cell_type":"markdown","source":["Last four digits of my BUID: 4,3,9,8.\n","The class label predicted for this bill by the logistic regression classifier is real. Yes, it is the same class as predicted by the KNN classifier."],"metadata":{"id":"vYMa1tuziPQd"}},{"cell_type":"markdown","source":["Question 6."],"metadata":{"id":"MSNXA4AjlU-o"}},{"cell_type":"markdown","source":["Q1."],"metadata":{"id":"CPVJywY5mNcK"}},{"cell_type":"code","source":["features = [\"variance\",\"skewness\",\"curtosis\",\"entropy\"]\n","\n","X = df[[\"variance\",\"skewness\",\"curtosis\",\"entropy\"]]\n","\n","#storing class labels \n","y = df[[\"class\"]]\n","\n","results_on_omitting_features = pd.DataFrame(columns=['F1','F2','F3','F4','accuracy','delta'])\n","\n","#Model with all features F1 through F4.\n","scaler = StandardScaler()\n","\n","#splitting data each time 50:50 train test split\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.5,random_state=42)\n","\n","#scaling training data (X_train)\n","X_train = scaler.fit_transform(X_train)\n","\n","#fitting classifier to training data\n","logReg.fit(X_train,y_train)\n","\n","#predicting labels and storing results in y_pred \n","y_pred = logReg.predict(X_test)\n","\n","accuracy  = accuracy_score(y_test,y_pred)\n","\n","results_on_omitting_features.loc[0] = [\"1\"]+[\"1\"]+[\"1\"]+[\"1\"]+[round(accuracy*100,2)]+[0]\n","\n","#iterates equal to number of features i.e 4 times\n","for i,f in enumerate(features):\n","\n","  #splitting data each time 50:50 train test split\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.5,random_state=42)\n","\n","  #dropping features from both train and test data\n","  X_train = X_train.drop([f],axis=1)\n","  \n","  X_test = X_test.drop([f],axis=1)\n","  \n","  scaler = StandardScaler()\n","\n","  logReg = LogisticRegression()\n","\n","  #scaling training data (X_train)\n","  X_train = scaler.fit_transform(X_train)\n","\n","  #fitting classifier to training data\n","  logReg.fit(X_train,y_train)\n","\n","  #predicting labels and storing results in y_pred \n","  y_pred = logReg.predict(X_test)\n","\n","  accuracy  = accuracy_score(y_test,y_pred)\n","\n","  #conditions to append data based on which feature is being ommited  \n","  if i == 0:\n","    results_on_omitting_features.loc[i+1] = [\"0\"]+[\"1\"]+[\"1\"]+[\"1\"]+ [round(accuracy*100,2)]+[ round(accuracy*100,2) - ( results_on_omitting_features.loc[0]['accuracy'] )]\n","\n","  elif i == 1:\n","    results_on_omitting_features.loc[i+1] = [\"1\"]+[\"0\"]+[\"1\"]+[\"1\"]+ [round(accuracy*100,2)]+[ round(accuracy*100,2) - ( results_on_omitting_features.loc[0]['accuracy'] )]\n","\n","  elif i == 2:\n","    results_on_omitting_features.loc[i+1] = [\"1\"]+[\"1\"]+[\"0\"]+[\"1\"]+ [round(accuracy*100,2)]+[ round(accuracy*100,2) - ( results_on_omitting_features.loc[0]['accuracy'] )]\n","\n","  elif i == 3:\n","    results_on_omitting_features.loc[i+1] = [\"1\"]+[\"1\"]+[\"1\"]+[\"0\"]+ [round(accuracy*100,2)]+[ round(accuracy*100,2) - ( results_on_omitting_features.loc[0]['accuracy'] )]\n","  \n"],"metadata":{"id":"7ujcwNAsFgh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_on_omitting_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"A7MqykIttGuQ","executionInfo":{"status":"ok","timestamp":1667075956063,"user_tz":240,"elapsed":4,"user":{"displayName":"Vicky Karkera","userId":"04341208707087360864"}},"outputId":"0a1d6462-1a56-40db-e0fe-c6a5f1ffbfb1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  F1 F2 F3 F4  accuracy  delta\n","0  1  1  1  1     84.11      0\n","1  0  1  1  1     65.60 -18.51\n","2  1  0  1  1     81.34  -2.77\n","3  1  1  0  1     82.65  -1.46\n","4  1  1  1  0     83.82  -0.29"],"text/html":["\n","  <div id=\"df-a4ea7181-3334-4bd2-925a-aedb708743c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1</th>\n","      <th>F2</th>\n","      <th>F3</th>\n","      <th>F4</th>\n","      <th>accuracy</th>\n","      <th>delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>84.11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>65.60</td>\n","      <td>-18.51</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>81.34</td>\n","      <td>-2.77</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>82.65</td>\n","      <td>-1.46</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>83.82</td>\n","      <td>-0.29</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4ea7181-3334-4bd2-925a-aedb708743c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a4ea7181-3334-4bd2-925a-aedb708743c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a4ea7181-3334-4bd2-925a-aedb708743c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Q2. No, Accuracy did not increase in any of the cases compared to when all 4 features were used."],"metadata":{"id":"sIkrsr9pig2m"}},{"cell_type":"markdown","source":["Q3. When F1 or variance was removed it contributed to the greatest loss in accuracy."],"metadata":{"id":"W4i6wR1Vigdc"}},{"cell_type":"markdown","source":["Q4. When F4 or entropy was removed it contributed to the least to loss of accuracy."],"metadata":{"id":"OP2nUsPQigKY"}},{"cell_type":"markdown","source":["Q5. \n","\n","No relative significance of features is not the same as obtained in KNN.\n","\n","In the case of KNN, removing the second feature which is skewness or F2, the model saw an increase of 0.14 in accuracy. Whereas in the case of logistic regression model none of the cases when we omitted a single feature while training, lead to an increase in the model accuracy.\n","\t\n","So in KNN we saw that the features when taken together namely - variance, curtosis, entropy, omitting skewness lead to increase in accuracy.Whereas in Logistic regression, omitting any feature lead to decrease in the models accuracy, compared to when all four features were used. \n"],"metadata":{"id":"afkBNPafif44"}}]}